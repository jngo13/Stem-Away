{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DistilBERT_C.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"a355HHOlVjW3","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CS46d5dZWQju","colab_type":"code","colab":{}},"source":["#Initiating the GPU\n","\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import os\n","import GPUtil as GPU\n","\n","GPUs = GPU.getGPUs()\n","\n","def printn():\n","  process = psutil.Process(os.getpid())\n","  print (\"Gen RAM free:\"+ humanize.naturalsize(psutil.virtual_memory.available), \" | Proc size:\"+ humanize.naturalsize(process.memory_info().rss))\n","  print (\"GPU RAM free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJui0t6bZGGk","colab_type":"code","colab":{}},"source":["#Importing required Python libraries\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","import re\n","import nltk\n","\n","nltk.download(\"punkt\")\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","\n","from html.parser import HTMLParser\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","\n","import time\n","import datetime\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N388D_LZa5eo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e1958ada-38a5-4eff-8c5a-11d7c9569019"},"source":["#Enabling cuda\n","\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","  print (\"There are %d GPUs available\"% torch.cuda.device_count())\n","  print (\"We will use the GPU:\", torch.cuda.get_device_name(0))\n","\n","else:\n","  print (\"No GPU available, using the CPU instead\")\n","  device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPUs available\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GSQQodE2b-rj","colab_type":"code","colab":{}},"source":["#Display the elapsed time when loading data into the model, rounded to the nearest second\n","\n","def format_time(elapsed):\n","  elapsed_rounded = int(round(elapsed))\n","  return str(datetime.timedelta(seconds = elapsed_rounded))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lR07BrQdcURi","colab_type":"code","colab":{}},"source":["def get_accuracy(pred,true):\n","  pred_flat = np.argmax(pred, axis = 1).flatten()\n","  true_flat = true.flatten()\n","  return np.sum(pred_flat == true_flat)/ len(true_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhHqc-oLczuQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"c3ce2b10-38ce-4d4f-89d2-c01d94dda2fb"},"source":["#Loading the data \n","\n","df = pd.read_csv(<mention path>)\n","df = df[:150000]\n","df.info()\n","df.drop('Unnamed: 0', axis = 1, inplace = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150000 entries, 0 to 149999\n","Data columns (total 6 columns):\n"," #   Column      Non-Null Count   Dtype \n","---  ------      --------------   ----- \n"," 0   Unnamed: 0  150000 non-null  int64 \n"," 1   Category    150000 non-null  object\n"," 2   Topics      150000 non-null  object\n"," 3   Content     150000 non-null  object\n"," 4   Tag         150000 non-null  object\n"," 5   Votes       150000 non-null  int64 \n","dtypes: int64(2), object(4)\n","memory usage: 6.9+ MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cxl9rJX1fda-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"eebd8c19-c1ff-4783-b9e4-eaa2be01a1b1"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Topics</th>\n","      <th>Content</th>\n","      <th>Tag</th>\n","      <th>Votes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sql</td>\n","      <td>When to use single quotes, double quotes, and ...</td>\n","      <td>I am trying to learn the best way ...</td>\n","      <td>['mysql', 'sql', 'quotes']</td>\n","      <td>642</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sql</td>\n","      <td>SQL injection that gets around mysql_real_esca...</td>\n","      <td>Is there an SQL injection possibil...</td>\n","      <td>['php', 'mysql', 'sql', 'security', 'sql-injec...</td>\n","      <td>654</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sql</td>\n","      <td>SQL select only rows with max value on a colum...</td>\n","      <td>I have this table for documents (s...</td>\n","      <td>['mysql', 'sql', 'aggregate-functions', 'great...</td>\n","      <td>1256</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sql</td>\n","      <td>Simulating group_concat MySQL function in Micr...</td>\n","      <td>I'm trying to migrate a MySQL-base...</td>\n","      <td>['sql', 'sql-server', 'sql-server-2005', 'stri...</td>\n","      <td>347</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sql</td>\n","      <td>Select first row in each GROUP BY group?</td>\n","      <td>As the title suggests, I'd like to...</td>\n","      <td>['sql', 'sqlite', 'postgresql', 'group-by', 'g...</td>\n","      <td>1366</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Category  ... Votes\n","0      Sql  ...   642\n","1      Sql  ...   654\n","2      Sql  ...  1256\n","3      Sql  ...   347\n","4      Sql  ...  1366\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"gjPr4om3fgzi","colab_type":"code","colab":{}},"source":["df['Category'].value_counts().plot(kind = 'barh', figsize = (10,10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gPOWoFVf43D","colab_type":"code","colab":{}},"source":["df['Category'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jB5QStow0m31","colab_type":"code","colab":{}},"source":["#Some cleaning steps to remove HTML tags, hash tags, new line, @ symbol and other special characters\n","\n","def text_cleaning(text):\n","  parser = HTMLParser()\n","  text = parser.unescape(text)\n","  text = text.lower()\n","  text = re.sub(r'<[^>]+>', '', text)\n","  text = re.sub(r'(?:\\#+[\\w_]+[\\w\\*_\\-]*[\\w_]+)', '', text)\n","  text = re.sub('@','', text)\n","  text = re.sub(r'(?:[\\ufffd]+)', '', text)\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFwdcjzp3zxm","colab_type":"code","colab":{}},"source":["topics = df['Topics'].apply(lambda x:text_cleaning(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DwNaYRL9gYwu","colab_type":"code","colab":{}},"source":["#Loading the transformer model, tokenizer\n","\n","try:\n","  import transformers as ppb\n","except:\n","  !pip install transformers\n","  import transformers as ppb\n","\n","from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n","\n","tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = ppb.DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = df['Category'].nunique())\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swwsOH8FiGYc","colab_type":"code","colab":{}},"source":["#Tokenizing the topics\n","\n","label_encoder = LabelEncoder()\n","inputs = []\n","attention_masks = []\n","\n","for topic in topics:\n","  encoded_dict = tokenizer.encode_plus(\n","      topic,\n","      add_special_tokens = True,\n","      truncation = True,\n","      max_length = 512,\n","      pad_to_max_length = True,\n","      return_overflowing_tokens = True,\n","      stride = 70,\n","      return_attention_mask = True,\n","      return_tensors = 'pt',\n","  )\n","  inputs.append(encoded_dict['input_ids']) #Adding encoded sentence and its attention mask to the list\n","  attention_masks.append(encoded_dict['attention_mask'])\n","\n","inputs = torch.cat(inputs, dim = 0) #Conversion of lists to tensors and loading of the same to GPU\n","attention_masks = torch.cat(attention_masks, dim = 0)\n","labels = label_encoder.fit_transform(df['Category']) #Encoding the labels\n","labels = torch.tensor(labels)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lrO92dW9pYKC","colab_type":"code","colab":{}},"source":["#Preparing training and validation dataset\n","\n","batch_size = 16\n","train_size = int(len(topics)*0.7)\n","val_size = int(len(topics)*0.1)\n","test_size = len(topics) - train_size - val_size\n","dataset = TensorDataset(inputs, attention_masks, labels)\n","train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n","train_loader = DataLoader(train_set, sampler = RandomSampler(train_set), batch_size = batch_size)\n","val_loader = DataLoader(val_set, sampler = SequentialSampler(val_set), batch_size = batch_size)\n","test_loader = DataLoader(test_set, sampler = SequentialSampler(test_set), batch_size = batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCeAKGhc8bdF","colab_type":"code","colab":{}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr=2e-5,\n","                  eps=1e-8)\n","epochs = 4\n","total_steps = len(train_loader)*epochs #Number of total training steps = (Number of batches)*(Number of epochs)\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvutI7wxBjiZ","colab_type":"code","colab":{}},"source":["#Training model\n","\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_log = []\n","for epoch in range(epochs):\n","  time_start= time.time()\n","  total_train_loss = 0\n","  print ('Begin training')\n","  print('')\n","  model.train()\n","  for step, batch in enumerate(train_loader):\n","    if step%10 == 0 and not step == 0:\n","      elapsed = format_time(time.time()- time_start)\n","      print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(train_loader),elapsed))\n","    \n","    b_inputs = batch[0].to(device)\n","    b_attention_masks = batch[1].to(device)\n","    b_label = batch[2].to(device)\n","\n","    model.zero_grad()\n","    loss, logit= model(b_inputs, attention_mask = b_attention_masks, labels= b_label)\n","\n","    optimizer.zero_grad()\n","    total_train_loss +=loss.item()\n","    loss.backward()\n","\n","    torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n","\n","    optimizer.step()\n","    scheduler.step()\n","\n","  avg_train_loss = total_train_loss/len(train_loader)\n","  training_time= format_time(time.time() - time_start)\n","  print('')\n","  print('Avg training loss: {0:.2f}'.format(avg_train_loss))\n","  print('Training epoch time: {:}'.format(training_time))\n","  print('')\n","  print('Begin validation')\n","  time_start = time.time()\n","  model.eval()\n","  total_eval_acc = 0\n","  total_eval_loss = 0\n","  nb_eval_steps = 0\n","  for batch in val_loader:\n","    b_inputs = batch[0].cuda()\n","    b_attention_masks = batch[1].cuda()\n","    b_label = batch[2].cuda()\n","\n","    with torch.nograd():\n","      (loss,logits)= model(b_inputs, attention_mask = b_attention_masks, labels=b_label)\n","\n","    total_eval_loss +=loss.item()\n","    logits = logits.detach().cpu().numpy()\n","    label = b_label.to('cpu').numpy()\n","\n","    total_eval_acc += get_accuracy(logits, label)\n","  avg_val_accuracy = total_eval_acc/len(val_loader)\n","  print(\"Accuracy: {0:.2f}\". format(avg_val_accuracy))\n","\n","  avg_val_loss = total_eval_loss/len(val_loader)\n","  validation_time= format_time(time.time()- time_start)\n","\n","  print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n","  print(\"Validation time: {:}\".format(validation_time))\n","\n","  training_log.append(\n","      {\n","          'epoch': epoch+1,\n","          'Training Loss': avg_train_loss,\n","          'Valid.Loss': avg_val_loss,\n","          'Valid.Accur.': avg_val_accuracy,\n","          'Training time':training_time,\n","          'Validation time': validation_time\n","      }\n","  )\n","print('Training complete')\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcxXjYWOzt4s","colab_type":"code","colab":{}},"source":["#Model evaluation\n","\n","model.eval()\n","pred_labels = []\n","true_labels = []\n","for batch in test_loader:\n","  b_inputs = batch[0].to(device)\n","  b_attention_masks = batch[1].to(device)\n","  b_label = batch[2].to(device)\n","\n","  with torch.no_grad():\n","    outputs = model(b_inputs, attention_mask = b_attention_masks)\n","  logits = outputs[0]\n","\n","  logits = logits.detach().cpu().numpy()\n","  labels = b_label.to('cpu').numpy()\n","\n","  pred_labels.append(logits)\n","  true_labels.append(labels)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"otoM4hfBf2vp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"4ba7e78b-ced0-4e02-9eba-5195053959d0"},"source":["flat_pred_labels = [item for sublist in pred_labels for item in sublist]\n","flat_pred_labels = np.argmax(flat_pred_labels, axis = 1).flatten()\n","\n","flat_true_labels = [item for sublist in true_labels for item in sublist]\n","\n","print(classification_report(flat_true_labels, flat_pred_labels))\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.85      0.96      0.90      7155\n","           1       0.70      0.10      0.18      1058\n","           2       0.97      0.99      0.98     10313\n","           3       0.89      0.88      0.89      3417\n","           4       0.98      0.96      0.97      8057\n","\n","    accuracy                           0.93     30000\n","   macro avg       0.88      0.78      0.78     30000\n","weighted avg       0.93      0.93      0.92     30000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KOxZjltJHZ_z","colab_type":"code","colab":{}},"source":["#Saving the model\n","# import os\n","# ouput_dir = <mention path>\n","\n","# if not os.path.exists(output_dir):\n","#   os.makedirs(output_dir)\n","\n","# print(\"Saving model to %s\"% output_dir)\n","\n","# model_to_save = model.module if hasattr(model,'module') else model\n","# model_to_save.save_pretrained(output_dir)\n","# tokenizer.save_pretrained(output_dir)"],"execution_count":null,"outputs":[]}]}